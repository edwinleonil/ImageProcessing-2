{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copy images from parent folder containing all images to another folder keeping the same forder name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import pandas as pd\n",
    "\n",
    "# use rl_env environment to run this script\n",
    "\n",
    "# The following code copies the images from the original_folder folder to a new folder under the ID of the image\n",
    "# This code helps only take the files that are needed for the defect dataset\n",
    "\n",
    "# ============================================================================================================\n",
    "# IMPORTANT: Do not run this code more than once as it will overwrite the images in the new folder\n",
    "# ============================================================================================================\n",
    "\n",
    "src_path = r\"folder_containing_images\" # this is the path to the folder containing the images\n",
    "dst_path = r\"destination_folder\" # this is the path to the folder where the images will be copied\n",
    "\n",
    "# list the subfolders of src_path\n",
    "subfolders = os.listdir(src_path)\n",
    "\n",
    "# count the number of subfolders\n",
    "subfolders_count = len(subfolders)\n",
    "\n",
    "# create an empty list to store the subfolders without the original_folder folder\n",
    "subfolders_without_original_folder = []\n",
    "\n",
    "# iterate through the subfolders under \"Production blades cropped 220314\"\n",
    "for i in range(subfolders_count):\n",
    "    # check if there is a folder called original_folder inside the subfolder\n",
    "    if os.path.exists(src_path + '/' + subfolders[i] + '/original_folder'):\n",
    "        # if the folder exists, list the files inside it\n",
    "        files = os.listdir(src_path + '/' + subfolders[i] + '/original_folder')\n",
    "        # iterate through the files\n",
    "        for file in files:\n",
    "            # if the file ends with Normal X.png, Normal Y.png, Normal Z.png, Curvature.png or .json copy it to the new folder\n",
    "            if file.endswith('Normals X.png') or file.endswith('Normals Y.png') or file.endswith('Normals Z.png') or file.endswith('Curvature.png') or file.endswith('.json'):\n",
    "                # if the files has been found, create a subfolder under the new folder\n",
    "                if not os.path.exists(dst_path + '/'+ subfolders[i]):\n",
    "                    # create a subfolder under the new folder                   \n",
    "                    os.makedirs(dst_path + '/' + subfolders[i])\n",
    "                # copy the image to the new folder under a subfolder called the second last part of the folder path\n",
    "                shutil.copy(src_path + '/' + subfolders[i] + '/original_folder/' + file, dst_path + '/' + subfolders[i] + '/')\n",
    "                 \n",
    "    else:\n",
    "        # create a list of subfolders without the original_folder folder in an accumulator      \n",
    "        subfolders_without_original_folder.append(subfolders[i])\n",
    "# save the list of subfolders without the original_folder folder in a text file\n",
    "with open('subfolders_missing_original_folder.txt', 'w') as f:\n",
    "    for item in subfolders_without_original_folder:\n",
    "        f.write(\"%s\\n\" % item)\n",
    "\n",
    "# display completed message\n",
    "print('Completed')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find the match file between the original image and the cropped images and store the file paths for each matched file in a csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write a code to count matching file names in two directories\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "import glob\n",
    "import pandas as pd\n",
    "\n",
    "# get directory path 1 that contains the class folders with images - comment out the path that is not needed\n",
    "path1 = r\"holdout_test\"\n",
    "\n",
    "# get directory path 2 that contains the blade folders with the defect images\n",
    "path2 = \"dataset\"\n",
    "\n",
    "# count the number of matching files names in two directories, the files are under subdirectories\n",
    "\n",
    "# get the list of subdirectories in path1\n",
    "subdir1 = os.listdir(path1)\n",
    "# get the list of subdirectories in path2\n",
    "subdir2 = os.listdir(path2)\n",
    "\n",
    "# create an empty dataframe\n",
    "df = pd.DataFrame(columns=['path1', 'path2','class'])\n",
    "\n",
    "# loop through each subdirectory in path1\n",
    "for i in range(len(subdir1)):\n",
    "    # create a list to store the number of matching files in each subdirectory\n",
    "    match = []\n",
    "    # get the list of files in each subdirectory in path1\n",
    "    files1 = os.listdir(path1 + \"\\\\\" + subdir1[i])\n",
    "    # iterate through each subdirectory in path2\n",
    "    for j in range(len(files1)):\n",
    "        \n",
    "        # iterate through each subdirectory in path2\n",
    "        for m in range(len(subdir2)):\n",
    "\n",
    "\n",
    "            # get the list of files in each subdirectory in path2\n",
    "            files2 = os.listdir(path2 + \"\\\\\" + subdir2[m])\n",
    "            \n",
    "            # iterate through each file in path1\n",
    "            for k in range(len(files2)):\n",
    "                # if the file name in path1 matches the file name in path2\n",
    "\n",
    "                if files1[j] == files2[k]:\n",
    "                    # record the file path of both files in a dataframe\n",
    "                    df2 = pd.DataFrame({'path1': [path1 + \"\\\\\" + subdir1[i] + \"\\\\\" + files1[j]], 'path2': [path2 + \"\\\\\" + subdir2[m] + \"\\\\\" + files2[k]], 'class': [subdir1[i]]})\n",
    "                    # append the dataframe to the empty dataframe\n",
    "                    df = pd.concat([df, df2], ignore_index=True)\n",
    "                else:\n",
    "                    # continue to the next file\n",
    "                    continue\n",
    "\n",
    "    # save the dataframe as a csv file\n",
    "    df.to_csv(\"csv_data/testMatchedFiles.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the number of matched files between two folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of files:  2063\n",
      "Number of files:  2063\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# load the csv file\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df = pd.read_csv('csv_data/trainMatchedFiles.csv')\n",
    "# df = pd.read_csv('matched_filepaths.csv')\n",
    "# print the length of the dataframe\n",
    "print('Number of files: ',len(df))\n",
    "\n",
    "df2 = pd.read_csv('csv_data/matched_filepaths.csv')\n",
    "\n",
    "# print the length of the dataframe\n",
    "print('Number of files: ',len(df2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display a sample of the matched files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "index = 500\n",
    "# Load the two images\n",
    "path_1 = df['path2'][index]\n",
    "path_2 = df['path1'][index]\n",
    "img1 = cv2.imread(path_2)\n",
    "img2 = cv2.imread(path_1)\n",
    "\n",
    "# resise the images to half the original size\n",
    "img1 = cv2.resize(img1, (0, 0), None, .3, .3)\n",
    "img2 = cv2.resize(img2, (0, 0), None, .3, .3)\n",
    "# display the images side by side as subplots\n",
    "fig = plt.figure(figsize=(10, 5))\n",
    "ax1 = fig.add_subplot(121)\n",
    "ax1.imshow(img1)\n",
    "ax2 = fig.add_subplot(122)\n",
    "ax2.imshow(img2)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get path of image files in a csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "def extract_paths(parent_folder_path):\n",
    "    # create an empty dataframe\n",
    "    df = pd.DataFrame(columns=['Subfolder', 'filename', 'filepath'])\n",
    "    # Loop through all subfolders in parent folder\n",
    "    for subfolder in os.listdir(parent_folder_path):\n",
    "        subfolder_path = os.path.join(parent_folder_path, subfolder)\n",
    "        \n",
    "        # Check if subfolder contains DefectsData folder\n",
    "        if \"DefectsData\" in os.listdir(subfolder_path):\n",
    "            defect_folder_path = os.path.join(subfolder_path, \"DefectsData\")\n",
    "            # Loop through all files in DefectsData folder\n",
    "            for file in os.listdir(defect_folder_path):\n",
    "                file_path = os.path.join(defect_folder_path, file)\n",
    "                \n",
    "                # Check if file ends with specified extensions\n",
    "                if file.endswith((\"A.png\", \"B.png\", \"C.png\", \"D.png\", \".json\")):\n",
    "                    # append the file path including the subfolder name to the dataframe\n",
    "                    df2 = pd.DataFrame([[subfolder, file, file_path]], columns=['Subfolder', 'filename', 'filepath'])\n",
    "                    df = pd.concat([df, df2], ignore_index=True)\n",
    "                    \n",
    "    # if the filepaths.csv file already exists, delete it\n",
    "    if os.path.exists('filepaths.csv'):\n",
    "        os.remove('original_filepaths.csv')\n",
    "\n",
    "     # save the dataframe as a csv file\n",
    "    df.to_csv('csv_data/original_filepaths.csv', index=False)              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parent_folder_path = r\"original_folder\" # this is the path to the folder containing the images\n",
    "\n",
    "# use the function extract_paths to get the paths to all the images in a csv file\n",
    "# the csv will be save in the current working directory\n",
    "extract_paths(parent_folder_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = r\"training\"\n",
    "# create a function to get the file names\n",
    "# the file names are in a subfolder of the folder_path\n",
    "# concatenate the in a data frame the subfolder name and the file name\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "def get_filenames(folder_path):\n",
    "    # create an empty dataframe\n",
    "    df = pd.DataFrame(columns=['subfolder', 'filename', 'filepath'])\n",
    "    # loop through the subfolders\n",
    "    for subfolder in os.listdir(folder_path):\n",
    "        # loop through the files in the subfolder\n",
    "        for file in os.listdir(os.path.join(folder_path, subfolder)):\n",
    "            if file == 'Thumbs.db':\n",
    "                continue\n",
    "            else:\n",
    "                # concatenate the subfolder name, the file path and the file name to the dataframe\n",
    "                df2 = pd.DataFrame({'label': subfolder, 'filename': file, 'filepath': os.path.join(folder_path, subfolder, file)}, index=[0])\n",
    "                df = pd.concat([df, df2], ignore_index=True)     \n",
    "\n",
    "    # if the file name already exists,rename the file name before saving it to the csv file\n",
    "    if os.path.exists('label_filenames.csv'):\n",
    "        os.remove('label_filenames.csv')\n",
    "\n",
    "    # save the dataframe to a csv file\n",
    "    df.to_csv('csv_data/label_filepaths.csv', index=False)\n",
    "\n",
    "\n",
    "# call the function\n",
    "get_filenames(folder_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look if file names match between the original files and the labeled files that are in two different csv files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load csv file\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# load csv file\n",
    "df_original = pd.read_csv('csv_data/original_filepaths.csv')\n",
    "df_labeled = pd.read_csv('csv_data/label_filepaths.csv')\n",
    "\n",
    "# if column filename matches between two dataframes, get the filepath from df_original and the label from df_labeled includign the filename and label\n",
    "\n",
    "# create a new dataframe with the filepath and label\n",
    "matched_df = pd.DataFrame(columns=['original_filepath', 'label_filepath','label'])\n",
    "\n",
    "# iterate through df_labeled\n",
    "for index, row in df_labeled.iterrows():\n",
    "    # get filename\n",
    "    filename = row['filename']\n",
    "    # get label\n",
    "    label = row['label']\n",
    "    # file path\n",
    "    filepath = row['filepath']\n",
    "    # find the row in df_original that has the same filename\n",
    "    original_row = df_original.loc[df_original['filename'] == filename]\n",
    "    # if there is no match, continue\n",
    "    if original_row.empty:\n",
    "        continue\n",
    "    else:\n",
    "        # get the filepath from df_original\n",
    "        original_filepath = original_row['filepath'].values[0]\n",
    "        # create a new row with the original_filepath, label_filepath, and label\n",
    "        df = pd.DataFrame([[original_filepath, filepath, label]], columns=['original_filepath', 'label_filepath','label'])\n",
    "        # concat the new row to matched_df\n",
    "        matched_df = pd.concat([matched_df, df], ignore_index=True)\n",
    "\n",
    "# save the new dataframe to a csv file\n",
    "matched_df.to_csv('csv_data/matched_filepaths.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display matched original file with its cropped image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "# load the images using the mached_df dataframe\n",
    "\n",
    "# load the matched dataframe\n",
    "matched_df = pd.read_csv('csv_data/matched_filepaths.csv')\n",
    "\n",
    "# Check if the file paths are valid\n",
    "orig_file_path = matched_df['original_filepath'][150]\n",
    "label_file_path = matched_df['label_filepath'][150]\n",
    "\n",
    "if not os.path.isfile(orig_file_path):\n",
    "    print(f\"Original file path does not exist: {orig_file_path}\")\n",
    "if not os.path.isfile(label_file_path):\n",
    "    print(f\"Label file path does not exist: {label_file_path}\")\n",
    "\n",
    "# Load the images\n",
    "img_orig = cv2.imread(orig_file_path)\n",
    "img_crop = cv2.imread(label_file_path)\n",
    "\n",
    "# Check if the images are loaded correctly\n",
    "if img_orig is None:\n",
    "    print(f\"Failed to load original image from: {orig_file_path}\")\n",
    "if img_crop is None:\n",
    "    print(f\"Failed to load cropped image from: {label_file_path}\")\n",
    "\n",
    "# If both images are loaded correctly, display them\n",
    "if img_orig is not None and img_crop is not None:\n",
    "    # show the images\n",
    "    plt.figure(figsize=(10,10))\n",
    "    plt.subplot(1,2,1)\n",
    "    plt.imshow(img_orig)\n",
    "    plt.subplot(1,2,2)\n",
    "    plt.imshow(img_crop)\n",
    "else:\n",
    "    print(\"Cannot display images due to loading errors.\")\n",
    "\n",
    "# save the images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get length of data and unique values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# load csv file called matched_filepaths.csv into dataframe\n",
    "df = pd.read_csv('csv_data/matched_filepaths.csv')\n",
    "\n",
    "# group the dataframe by the label column\n",
    "grouped = df.groupby('label')\n",
    "\n",
    "\n",
    "# get the name of the groups\n",
    "labels = grouped.groups.keys()\n",
    "\n",
    "# print he key name of the dictionary labels for the second key\n",
    "label = list(labels)[2]\n",
    "\n",
    "# get the group for the label\n",
    "group = grouped.get_group(label)\n",
    "\n",
    "# get length of group\n",
    "length = len(df)\n",
    "\n",
    "print(length)\n",
    "\n",
    "# count the number rows in the dataframe\n",
    "count = df.count()\n",
    "\n",
    "# count the unique values in the path1 column\n",
    "unique = df['original_filepath'].unique()\n",
    "print(unique)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# command to clear jupiter workspace\n",
    "%reset -f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the x,y, width and height of the bounding box of the object as int values and save them as csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display image with bounding box using PIL\n",
    "import os\n",
    "import random\n",
    "import csv\n",
    "import pandas as pd\n",
    "\n",
    "# load csv file called labeldata.csv\n",
    "df = pd.read_csv('TemplateMatchingResultsTable.csv')\n",
    "\n",
    "# split the matchLoc and matchSize columns into two columns each\n",
    "df[['x', 'y']] = df['MatchLoc'].str.split(',', expand=True)\n",
    "df[['w', 'h']] = df['MatchSize'].str.split(',', expand=True)\n",
    "\n",
    "# drop the matchLoc and matchSize columns\n",
    "df = df.drop(columns=['MatchLoc', 'MatchSize'])\n",
    "\n",
    "# reorder the columns so that the original_filepath is first\n",
    "df = df[['original_filepath', 'label', 'x', 'y', 'w', 'h']]\n",
    "\n",
    "# find the center point of the bbox\n",
    "df['x'] = df['x'].astype(int)\n",
    "df['y'] = df['y'].astype(int)\n",
    "df['w'] = df['w'].astype(int)\n",
    "df['h'] = df['h'].astype(int)\n",
    "\n",
    "# save the new csv file\n",
    "df.to_csv('bboxvaluesInt.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display sample of images of the original image and its cropped image with the bounding box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display image with bounding box using PIL\n",
    "import os\n",
    "from PIL import Image, ImageDraw\n",
    "import numpy as np\n",
    "import random\n",
    "import csv\n",
    "import pandas as pd\n",
    "\n",
    "# load csv file called labeldata.csv\n",
    "df = pd.read_csv('csv_data/bboxvaluesInt.csv')\n",
    "\n",
    "index = 100\n",
    "# path to the images\n",
    "path = df['original_filepath'][index]\n",
    "label = df['label'][index]\n",
    "file_name = os.path.basename(path)\n",
    "\n",
    "# read the image with PIL\n",
    "image_org = Image.open(path)\n",
    "\n",
    "# get the image size\n",
    "width_org, height_org = image_org.size\n",
    "\n",
    "# calculate a ratio when the image is resized to 640x640\n",
    "w_ratio = 640 / width_org\n",
    "h_ratio = 640 / height_org\n",
    "\n",
    "# resize the image keeping the aspect ratio\n",
    "image = image_org.resize((int(width_org * w_ratio), int(height_org * h_ratio)))\n",
    "\n",
    "# convert the image to RGB\n",
    "image = image.convert('RGB')\n",
    "\n",
    "draw = ImageDraw.Draw(image)\n",
    "\n",
    "x = int(df['x'][index])\n",
    "y = int(df['y'][index])\n",
    "w = int(df['w'][index])\n",
    "h = int(df['h'][index])\n",
    "\n",
    "# multiply the bounding box coordinates by the ratio\n",
    "x = int(x * w_ratio)\n",
    "y = int(y * h_ratio)\n",
    "w = int(w * w_ratio)\n",
    "h = int(h * h_ratio)\n",
    "\n",
    "# draw the box\n",
    "draw.rectangle([x, y, x+w, y+h], outline=(0,256,126), width=2)\n",
    "\n",
    "# show the image\n",
    "image.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resize the image and its bbox to 640x640 and select one class for saving data for obj detection using YOLO v8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  resize the images\n",
    "import os\n",
    "from PIL import Image, ImageDraw\n",
    "import numpy as np\n",
    "import random\n",
    "import csv\n",
    "import pandas as pd\n",
    "\n",
    "save_path = 'data/train/'\n",
    "\n",
    "# load csv file \n",
    "df_org = pd.read_csv('csv_data/bboxvaluesInt.csv')\n",
    "\n",
    "# categorize df by labels\n",
    "df_org = df_org.groupby('label')\n",
    "\n",
    "# get the group names\n",
    "group_names = df_org.groups.keys()\n",
    "\n",
    "# create a new DataFrame for the first group for the label\n",
    "\n",
    "# create a new data frame containing the A,B,C labels - only apply this for HAB, MAB and LAB - comment otherwise\n",
    "df = pd.concat([df_org.get_group('A'), df_org.get_group('B'), df_org.get_group('C')], ignore_index=True)\n",
    "\n",
    "# iterate through the rows of the DataFrame\n",
    "for index, row in df.iterrows():\n",
    "    # path to the images\n",
    "    path = df['original_filepath'][index]\n",
    "    label = df['label'][index]\n",
    "    file_name = os.path.basename(path)\n",
    "\n",
    "    # read the image with PIL\n",
    "    image_org = Image.open(path)\n",
    "\n",
    "    # get the image size\n",
    "    width_org, height_org = image_org.size\n",
    "\n",
    "    # resize the image keeping the aspect ratio\n",
    "\n",
    "    # calculate a ratio when the image is resized to 640x640\n",
    "    w_ratio = 640 / width_org\n",
    "    h_ratio = 640 / height_org\n",
    "\n",
    "    # resize the image\n",
    "    image = image_org.resize((int(width_org * w_ratio), int(height_org * h_ratio)))\n",
    "\n",
    "    label = 'SecondaryGrain' # Only apply this for MAB, HAB and LAB - comment otherwise\n",
    "\n",
    "    # check if a folder name 'label' exists under  the data folder and if dont create one\n",
    "    if not os.path.exists(save_path+label):\n",
    "        os.mkdir(save_path+label)\n",
    "    \n",
    "    # save the resized image to the data folder under the label folder\n",
    "    # image.save(save_path+label+'/'+file_name)\n",
    "    image.save(save_path+label+'/'+file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below is the same as the previous with the difference that it also saves the images and the csv file with the bbox values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resize the images and their bbox coordinates\n",
    "import os\n",
    "from PIL import Image, ImageDraw\n",
    "import numpy as np\n",
    "import random\n",
    "import csv\n",
    "\n",
    "# load csv file \n",
    "df_org = pd.read_csv('bboxvaluesInt.csv')\n",
    "\n",
    "# categorize df by labels\n",
    "df_org = df_org.groupby('label')\n",
    "\n",
    "# get the group names\n",
    "group_names = df_org.groups.keys()\n",
    "\n",
    "# create a new DataFrame for the first group for the Pinsite label\n",
    "df = df_org.get_group('Scale')\n",
    "\n",
    "\n",
    "# iterate through the rows of the DataFrame\n",
    "for index, row in df.iterrows():\n",
    "    # path to the images\n",
    "    path = df['original_filepath'][index]\n",
    "    label = df['label'][index]\n",
    "    file_name = os.path.basename(path)\n",
    "\n",
    "    # read the image with PIL\n",
    "    image_org = Image.open(path)\n",
    "\n",
    "    # get the image size\n",
    "    width_org, height_org = image_org.size\n",
    "\n",
    "    # resize the image keeping the aspect ratio\n",
    "\n",
    "    # calculate a ratio when the image is resized to 640x640\n",
    "    w_ratio = 640 / width_org\n",
    "    h_ratio = 640 / height_org\n",
    "\n",
    "    # resize the image\n",
    "    image = image_org.resize((int(width_org * w_ratio), int(height_org * h_ratio)))\n",
    "\n",
    "    # check if a folder name 'label' exists under  the data folder and if dont create one\n",
    "    if not os.path.exists('data/'+label):\n",
    "        os.mkdir('data/'+label)\n",
    "\n",
    "    # save the resized image to the data folder under the label folder\n",
    "    image.save('data/'+label+'/'+file_name)\n",
    "\n",
    "    # convert the image to RGB\n",
    "    image = image.convert('RGB')\n",
    "\n",
    "    draw = ImageDraw.Draw(image)\n",
    "\n",
    "    x = int(df['x'][index])\n",
    "    y = int(df['y'][index])\n",
    "    w = int(df['w'][index])\n",
    "    h = int(df['h'][index])\n",
    "\n",
    "    # multiply the bounding box coordinates by the ratio\n",
    "    x = int(x * w_ratio)\n",
    "    y = int(y * h_ratio)\n",
    "    w = int(w * w_ratio)\n",
    "    h = int(h * h_ratio)\n",
    "\n",
    "    # draw the box\n",
    "    draw.rectangle([x, y, x+w, y+h], outline=(0,256,126), width=2)\n",
    "\n",
    "    # update the DataFrame with the new image path and the new coordinates\n",
    "    df.loc[index,'original_filepath'] = file_name\n",
    "    df.loc[index,'x'] = x\n",
    "    df.loc[index,'y'] = y\n",
    "    df.loc[index,'w'] = w\n",
    "    df.loc[index,'h'] = h\n",
    "\n",
    "    # if the csv file already exists, delete it\n",
    "    if os.path.exists('resizedData.csv'):\n",
    "        os.remove('resizedData.csv')\n",
    "    # save the updated DataFrame as a CSV file\n",
    "    df.to_csv('resizedData.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "normalize the x, y and w, h values to be between 0 and 1 - to prepare data for Yolo v8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import PIL\n",
    "from PIL import Image\n",
    "\n",
    "df = pd.read_csv('resizedData.csv')\n",
    "\n",
    "df['x_center'] = df['x'] + (df['w'] / 2)\n",
    "df['y_center'] = df['y'] + (df['h'] / 2)\n",
    "\n",
    "# add two columns for the normalized width and height\n",
    "df['norm_w'] = df['w']\n",
    "df['norm_h'] = df['h']\n",
    "\n",
    "for i in range(len(df)):\n",
    "    #read the image size by reading the original_filepath with PIL\n",
    "    img = PIL.Image.open('data/A/'+df['original_filepath'][i])\n",
    "    # get the image size\n",
    "    \n",
    "    width, height = img.size\n",
    "    # normalize the center and width and height\n",
    "    df.loc[i,'x_center'] = df.loc[i,'x_center'] / width\n",
    "    df.loc[i,'y_center'] = df.loc[i,'y_center'] / height\n",
    "    df.loc[i,'norm_w'] = df.loc[i,'norm_w'] / width\n",
    "    df.loc[i,'norm_h'] = df.loc[i,'norm_h'] / height\n",
    "\n",
    "# save the new csv file\n",
    "df.to_csv('anotationdata.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# command to clear jupiter workspace\n",
    "%reset -f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save annotation data to txt files of each image - to train with Yolo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load a csv file\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# read the csv file\n",
    "df = pd.read_csv('anotationdata.csv')\n",
    "\n",
    "# iterate through the rows of the csv file\n",
    "for index, row in df.iterrows():\n",
    "    \n",
    "    # get the x_center, y_center, norm_width, norm_height \n",
    "    file_name = row['original_filepath']\n",
    "    x_center = row['x_center']\n",
    "    y_center = row['y_center']\n",
    "    norm_width = row['norm_w']\n",
    "    norm_height = row['norm_h']   \n",
    "\n",
    "    # the txt file should be saved inside a subfolder called data/anotations\n",
    "    with open('data/anotations/' + file_name[:-4] + '.txt', 'w') as f:\n",
    "        f.write(str(0) + ' ' + str(x_center) + ' ' + str(y_center) + ' ' + str(norm_width) + ' ' + str(norm_height))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scale the bounding box values to the new image size - 640x640"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# read the CSV file\n",
    "df = pd.read_csv(r'C:\\Users\\me1elar\\Documents\\GitHub\\AI-23-19-AVI-ImageProcessingAndPrototypes\\csv_data\\TemplateMatchingResultsTable.csv')\n",
    "\n",
    "# scale the bounding box coordinates that are found in the MatchLoc and MatchSize columns\n",
    "df[['x', 'y']] = df['MatchLoc'].str.split(',', expand=True)\n",
    "df[['w', 'h']] = df['MatchSize'].str.split(',', expand=True)\n",
    "\n",
    "# scale the bounding box coordinates in relation to the image resize from 2752x2200 to 640x640\n",
    "df['x'] = (df['x'].astype(int) * (640 / 2752)).astype(int)\n",
    "df['y'] = (df['y'].astype(int) * (640 / 2200)).astype(int)\n",
    "\n",
    "df['w'] = (df['w'].astype(int) * (640 / 2752)).astype(int)\n",
    "df['h'] = (df['h'].astype(int) * (640 / 2200)).astype(int)\n",
    "\n",
    "# drop the following columns: label_filepath, MatchScore, MatchLoc, MatchSize\n",
    "df = df.drop(columns=['label_filepath', 'MatchScore', 'MatchLoc', 'MatchSize'])\n",
    "\n",
    "# get the last part of the path for each value in the original_filepath column\n",
    "df['original_filepath'] = df['original_filepath'].apply(lambda x: os.path.basename(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "folder_path = 'data/A_equ'\n",
    "file_list = os.listdir(folder_path)\n",
    "\n",
    "# the label name is the second part of the folder path\n",
    "label = 'A'\n",
    "\n",
    "# Get the index of the image you want to display\n",
    "index = 9 # index 50 is wrong\n",
    "\n",
    "file_name = file_list[index]\n",
    "\n",
    "# Get the file name and label from the data frame\n",
    "file_name = df.loc[df['original_filepath'].str.contains(file_name) & (df['label'] == label), 'original_filepath']\n",
    "print(file_name)\n",
    "file_name = file_name.values[0]\n",
    "# Get the file path and bounding box coordinates from the data frame\n",
    "file_path = os.path.join(folder_path, file_name)\n",
    "x = df.loc[df['original_filepath'] == file_name, 'x'].values[0]\n",
    "y = df.loc[df['original_filepath'] == file_name, 'y'].values[0]\n",
    "w = df.loc[df['original_filepath'] == file_name, 'w'].values[0]\n",
    "h = df.loc[df['original_filepath'] == file_name, 'h'].values[0]\n",
    "\n",
    "# Load the image\n",
    "image = cv2.imread(file_path)\n",
    "\n",
    "# Draw the bounding box on the image\n",
    "cv2.rectangle(image, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "\n",
    "# Convert the image from BGR to RGB\n",
    "image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "# Display the image with the bounding box\n",
    "plt.imshow(image_rgb)\n",
    "plt.axis('off')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1 Convert the x & y values of the bbox to center points and normalize them including the width and height of the bbox to be between 0 and 1 \n",
    "2 Save the data to a txt file for each bbox of each image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# read the CSV file\n",
    "df = pd.read_csv(r'csv_data\\TemplateMatchingResultsTable.csv')\n",
    "\n",
    "# scale the bounding box coordinates that are found in the MatchLoc and MatchSize columns\n",
    "df[['x', 'y']] = df['MatchLoc'].str.split(',', expand=True)\n",
    "df[['w', 'h']] = df['MatchSize'].str.split(',', expand=True)\n",
    "\n",
    "# scale the bounding box coordinates in relation to the image resize from 2752x2200 to 640x640\n",
    "df['x'] = (df['x'].astype(int) * (640 / 2752)).astype(int)\n",
    "df['y'] = (df['y'].astype(int) * (640 / 2200)).astype(int)\n",
    "\n",
    "df['w'] = (df['w'].astype(int) * (640 / 2752)).astype(int)\n",
    "df['h'] = (df['h'].astype(int) * (640 / 2200)).astype(int)\n",
    "\n",
    "# drop the following columns: label_filepath, MatchScore, MatchLoc, MatchSize\n",
    "df = df.drop(columns=['label_filepath', 'MatchScore', 'MatchLoc', 'MatchSize'])\n",
    "\n",
    "# keep only the last part of the path for each value in the original_filepath column\n",
    "df['original_filepath'] = df['original_filepath'].apply(lambda x: os.path.basename(x))\n",
    "\n",
    "# add new columns for the center points of the bounding box\n",
    "df['x_center'] = df['x'] + (df['w'] / 2)\n",
    "df['y_center'] = df['y'] + (df['h'] / 2)\n",
    "\n",
    "# add two columns for the normalized width and height of the bounding box\n",
    "df['norm_w'] = df['w']\n",
    "df['norm_h'] = df['h']\n",
    "\n",
    "\n",
    "width = 640\n",
    "height = 640\n",
    "# normalize the center and width and height of the bounding box\n",
    "df['x_center_norm'] = df['x_center'] / width\n",
    "df['y_center_norm'] = df['y_center'] / height\n",
    "df['norm_w'] = df['norm_w'] / width\n",
    "df['norm_h'] = df['norm_h'] / height\n",
    "\n",
    "# move norm_w and norm_h to the last two columns of the dataframe\n",
    "cols = list(df.columns.values)\n",
    "cols.pop(cols.index('norm_w'))\n",
    "cols.pop(cols.index('norm_h'))\n",
    "df = df[cols+['norm_w', 'norm_h']]\n",
    "\n",
    "# drop the x_center and y_center columns\n",
    "df = df.drop(columns=['x_center', 'y_center'])\n",
    "\n",
    "# rename the column original_filepath to file_id\n",
    "df = df.rename(columns={'original_filepath': 'file_id'})\n",
    "\n",
    "# add a column to represent the labels as int values starting from zero\n",
    "df['label'] = df['label'].astype('category')\n",
    "df['label_id'] = df['label'].cat.codes\n",
    "\n",
    "# save the label_id, x_center_norm, y_center_norm, norm_w, norm_h columns to a txt file with the file_id as the file name. If the file already exists, append the new values to the file\n",
    "for index, row in df.iterrows():\n",
    "    file_id = row['file_id']\n",
    "    label_id = row['label_id']\n",
    "    x_center_norm = row['x_center_norm']\n",
    "    y_center_norm = row['y_center_norm']\n",
    "    norm_w = row['norm_w']\n",
    "    norm_h = row['norm_h']\n",
    "    with open('csv_data/all_data_anotations/' + file_id[:-4] + '.txt', 'a') as f:\n",
    "        f.write(str(label_id) + ' ' + str(x_center_norm) + ' ' + str(y_center_norm) + ' ' + str(norm_w) + ' ' + str(norm_h) + '\\n')\n",
    "\n",
    "     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check for txt files with more than one bbox information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0 0.46796875 0.4703125 0.1390625 0.61875\\n', '8 0.546875 0.3859375 0.034375 0.103125\\n']\n"
     ]
    }
   ],
   "source": [
    "# search for a txt file in csv_data/all_data_anotations folder and open it\n",
    "import os\n",
    "\n",
    "# get the path to the txt file\n",
    "path = \"test.png\"\n",
    "path = path[:-4] + '.txt'\n",
    "path = os.path.join('csv_data/all_data_anotations', path)\n",
    "\n",
    "# open the txt file and read the lines\n",
    "with open(path) as f:\n",
    "    lines = f.readlines()\n",
    "\n",
    "print(lines)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Script to annotate A, B, C and D with their corresponding bbox values and save them to a txt file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# read the CSV file\n",
    "df = pd.read_csv(r'\\csv_data\\TemplateMatchingResultsTable.csv')\n",
    "\n",
    "# remove the rows that have a label D, E, A, B, C\n",
    "df = df[df.label != 'D']\n",
    "df = df[df.label != 'E']\n",
    "df = df[df.label != 'A']\n",
    "df = df[df.label != 'B']\n",
    "df = df[df.label != 'C']\n",
    "\n",
    "\n",
    "# scale the bounding box coordinates that are found in the MatchLoc and MatchSize columns\n",
    "df[['x', 'y']] = df['MatchLoc'].str.split(',', expand=True)\n",
    "df[['w', 'h']] = df['MatchSize'].str.split(',', expand=True)\n",
    "\n",
    "# scale the bounding box coordinates in relation to the image resize from 2752x2200 to 640x640\n",
    "df['x'] = (df['x'].astype(int) * (640 / 2752)).astype(int)\n",
    "df['y'] = (df['y'].astype(int) * (640 / 2200)).astype(int)\n",
    "\n",
    "df['w'] = (df['w'].astype(int) * (640 / 2752)).astype(int)\n",
    "df['h'] = (df['h'].astype(int) * (640 / 2200)).astype(int)\n",
    "\n",
    "# drop the following columns: label_filepath, MatchScore, MatchLoc, MatchSize\n",
    "df = df.drop(columns=['label_filepath', 'MatchScore', 'MatchLoc', 'MatchSize'])\n",
    "\n",
    "# keep only the last part of the path for each value in the original_filepath column\n",
    "df['original_filepath'] = df['original_filepath'].apply(lambda x: os.path.basename(x))\n",
    "\n",
    "# add new columns for the center points of the bounding box\n",
    "df['x_center'] = df['x'] + (df['w'] / 2)\n",
    "df['y_center'] = df['y'] + (df['h'] / 2)\n",
    "\n",
    "# add two columns for the normalized width and height of the bounding box\n",
    "df['norm_w'] = df['w']\n",
    "df['norm_h'] = df['h']\n",
    "\n",
    "\n",
    "width = 640\n",
    "height = 640\n",
    "# normalize the center and width and height of the bounding box\n",
    "df['x_center_norm'] = df['x_center'] / width\n",
    "df['y_center_norm'] = df['y_center'] / height\n",
    "df['norm_w'] = df['norm_w'] / width\n",
    "df['norm_h'] = df['norm_h'] / height\n",
    "\n",
    "# move norm_w and norm_h to the last two columns of the dataframe\n",
    "cols = list(df.columns.values)\n",
    "cols.pop(cols.index('norm_w'))\n",
    "cols.pop(cols.index('norm_h'))\n",
    "df = df[cols+['norm_w', 'norm_h']]\n",
    "\n",
    "# drop the x_center and y_center columns\n",
    "df = df.drop(columns=['x_center', 'y_center'])\n",
    "\n",
    "# rename the column original_filepath to file_id\n",
    "df = df.rename(columns={'original_filepath': 'file_id'})\n",
    "\n",
    "# add a column to represent the labels as int values starting from zero\n",
    "df['label'] = df['label'].astype('category')\n",
    "df['label_id'] = df['label'].cat.codes\n",
    "\n",
    "# save the label_id, x_center_norm, y_center_norm, norm_w, norm_h columns to a txt file with the file_id as the file name. If the file already exists, append the new values to the file\n",
    "for index, row in df.iterrows():\n",
    "    file_id = row['file_id']\n",
    "    label_id = row['label_id']\n",
    "    x_center_norm = row['x_center_norm']\n",
    "    y_center_norm = row['y_center_norm']\n",
    "    norm_w = row['norm_w']\n",
    "    norm_h = row['norm_h']\n",
    "    with open('csv_data/FourLabelsAnotations/' + file_id[:-4] + '.txt', 'a') as f:\n",
    "        f.write(str(label_id) + ' ' + str(x_center_norm) + ' ' + str(y_center_norm) + ' ' + str(norm_w) + ' ' + str(norm_h) + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the original test dataset as full images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  resize the images\n",
    "import os\n",
    "from PIL import Image, ImageDraw\n",
    "import numpy as np\n",
    "import random\n",
    "import csv\n",
    "import pandas as pd\n",
    "\n",
    "# load csv file \n",
    "df_org = pd.read_csv('csv_data/testMatchedFiles.csv')\n",
    "\n",
    "# rename the column path1 to original_filepath\n",
    "df_org = df_org.rename(columns={'path1': 'defect_filepath'})\n",
    "# rename the column path2 to defect_filepath\n",
    "df_org = df_org.rename(columns={'path2': 'original_filepath'})\n",
    "# rename the column class to label\n",
    "df_org = df_org.rename(columns={'class': 'label'})\n",
    "\n",
    "# categorize df by labels\n",
    "df_org = df_org.groupby('label')\n",
    "\n",
    "# get the group names\n",
    "group_names = df_org.groups.keys()\n",
    "\n",
    "# create a new DataFrame for the first group for the HAB, MAB and LAB labels\n",
    "df = df_org.get_group('A')\n",
    "\n",
    "\n",
    "\n",
    "# iterate through the rows of the DataFrame\n",
    "for index, row in df.iterrows():\n",
    "    # path to the images\n",
    "    path = df['original_filepath'][index]\n",
    "    label = df['label'][index]\n",
    "    file_name = os.path.basename(path)\n",
    "\n",
    "    # read the image with PIL\n",
    "    image_org = Image.open(path)\n",
    "\n",
    "    # get the image size\n",
    "    width_org, height_org = image_org.size\n",
    "\n",
    "    # resize the image keeping the aspect ratio\n",
    "\n",
    "    # calculate a ratio when the image is resized to 640x640\n",
    "    w_ratio = 640 / width_org\n",
    "    h_ratio = 640 / height_org\n",
    "\n",
    "    # resize the image\n",
    "    image = image_org.resize((int(width_org * w_ratio), int(height_org * h_ratio)))\n",
    "\n",
    "    label = 'SecondaryGrain' # Only apply this for MAB, HAB and LAB - comment otherwise\n",
    "    \n",
    "    # check if a folder name 'label' exists under  the data folder and if dont create one\n",
    "    if not os.path.exists('data/test/'+label):\n",
    "        os.mkdir('data/test/'+label)\n",
    "\n",
    "    # save the resized image to the data folder under the label folder\n",
    "    image.save('data/test/'+label+'/'+file_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  resize the images\n",
    "import os\n",
    "from PIL import Image, ImageDraw\n",
    "import numpy as np\n",
    "import random\n",
    "import csv\n",
    "import pandas as pd\n",
    "\n",
    "# load csv file \n",
    "df = pd.read_csv('csv_data/testMatchedFiles.csv')\n",
    "\n",
    "# change the Machine_scar class to MachineScar\n",
    "df = df.replace('Machine_scar', 'MachineScar')\n",
    "\n",
    "# save as a csv file called testMatchedFiles.csv\n",
    "df.to_csv('csv_data/testMatchedFiles.csv', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Move txt label files from the training dataset to the val dataset according to the val image files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# val folder path\n",
    "img_val_folder = r\"dataset\\images\\val\"\n",
    "\n",
    "# train folder path\n",
    "img_train_folder = r\"dataset\\images\\train\"\n",
    "\n",
    "# get the list of files in the val folder\n",
    "img_val_files = os.listdir(img_val_folder)\n",
    "\n",
    "# get the list of files in the train folder\n",
    "img_train_files = os.listdir(img_train_folder)\n",
    "\n",
    "# check that the files in the val folder are not in the train folder\n",
    "counter = 0\n",
    "for file in img_val_files:\n",
    "    if file in img_train_files:\n",
    "        counter += 1\n",
    "        # remove the file from the img_train_folder\n",
    "        # os.remove(os.path.join(img_train_folder, file))\n",
    "\n",
    "        print(f\"File {file} is in both folders\")\n",
    "print(f\"Number of files in both folders: {counter}\")\n",
    "\n",
    "# remove the files that are in both folders from the img_train_folder\n",
    "for file in img_val_files:\n",
    "    if file in img_train_files:\n",
    "        # remove the file from the img_train_folder\n",
    "        os.remove(os.path.join(img_train_folder, file))\n",
    "\n",
    "\n",
    "# train label folder path\n",
    "label_train_folder = r\"dataset\\labels\\train\"\n",
    "\n",
    "# val label folder path\n",
    "label_val_folder = r\"dataset\\labels\\val\"\n",
    "\n",
    "# move the txt files that are in te label_train_folder to the label_val_folder if these files names match the files names in the img_val_folder\n",
    "for file in img_val_files:\n",
    "    file_path = os.path.join(label_train_folder, file[:-4] + '.txt')\n",
    "\n",
    "    if os.path.exists(file_path):\n",
    "        # move the txt file from label_train_folder to label_val_folder\n",
    "        source_path = os.path.join(label_train_folder, file[:-4] + '.txt')\n",
    "        destination_path = os.path.join(label_val_folder, file[:-4] + '.txt')\n",
    "        # replace the file in the destination folder if it already exists\n",
    "        if os.path.exists(destination_path):\n",
    "            os.remove(destination_path)\n",
    "        os.rename(source_path, destination_path)\n",
    "    else:\n",
    "        print(f\"File {file} does not exist in the label_train_folder\")\n",
    "        \n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply image equalization to the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from skimage import data, exposure, img_as_float, io, color, img_as_ubyte\n",
    "import os\n",
    "\n",
    "# get the path of files inside the folder data/Pinsite\n",
    "path = 'data/test/ABC'\n",
    "\n",
    "files = os.listdir(path)\n",
    "\n",
    "# iterate through the files and apply the histogram equalization\n",
    "for file in files:\n",
    "    img = io.imread(os.path.join(path, file))\n",
    "    # print(img.shape)\n",
    "    img_eq = exposure.equalize_adapthist(img_as_float(img))\n",
    "    # Convert the image to RGB mode\n",
    "    img_rgb = color.gray2rgb(img_eq)\n",
    "    # convert to uint8\n",
    "    img_rgb = img_as_ubyte(img_rgb)\n",
    "    # save the image to the same folder\n",
    "    io.imsave(os.path.join(path, file), img_rgb)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clear the jupiter workspace\n",
    "%reset -f\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyword",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
